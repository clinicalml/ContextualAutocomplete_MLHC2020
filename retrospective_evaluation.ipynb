{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shelve\n",
    "import marisa_trie\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load rankers for labs, meds, symptoms, and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from med_lab_autocomplete_utils import LabAutocomplete, MedAutocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symptom_utils.symptom_autocomplete_utils import SymptomAutocomplete\n",
    "from symptom_utils.symptom_autocomplete_inferior_models import SymptomAutocompleteChiefComplaint, SymptomAutocompleteLR, SymptomAutocompleteNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_autocomplete = LabAutocomplete()\n",
    "medication_autocomplete = MedAutocomplete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 0.20.4 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.20.4 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.4 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BernoulliNB from version 0.20.4 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "symptom_autocomplete = SymptomAutocomplete();\n",
    "symptom_cc = SymptomAutocompleteChiefComplaint();\n",
    "symptom_lr =  SymptomAutocompleteLR();\n",
    "symptom_nb = SymptomAutocompleteNB();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "* ED data contains triage information and notes written in the emergency department, per patient (shuffled in a random order).\n",
    "* OMR/EHR data refers to all prior clinical notes in a patient's record (keyed by PatientID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ED and EHR (prior medical record) data...\n"
     ]
    }
   ],
   "source": [
    "print('Loading ED and EHR (prior medical record) data...')\n",
    "ed_visits_pkl = pickle.load(open('/data/BIDMC/ed_data/visits_full.pkl'))\n",
    "omr_data = shelve.open('/data/BIDMC/ed_data/omr/omrShelfPatient_py3_jclinic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Chief Complaints per ED \n"
     ]
    }
   ],
   "source": [
    "print('Load Chief Complaints per ED ')\n",
    "with open('/data/BIDMC/jclinic/extracted_data/ed_chief_complaints.pkl', 'rb') as h:\n",
    "    ed_chief_complaints = pickle.load(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open ontologies and create trie-based datastructure to find clinical concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpi_ontology = pd.read_csv('ontologies/hpi_autocomplete_ontology.csv', index_col=0)\n",
    "hpi_ontology['synonyms'] = hpi_ontology['synonyms'].apply(pd.eval)\n",
    "symptom_ontology = pd.read_csv('ontologies/symptom_autocomplete_ontology.csv')\n",
    "symptom_ontology['synonyms'] = symptom_ontology['synonyms'].apply(pd.eval)\n",
    "with open('ontologies/medication_ontology.json', 'r') as h:\n",
    "    med_list = json.load(h)['freq']\n",
    "with open('ontologies/lab_ontology.json', 'r') as h:\n",
    "    lab_list = json.load(h)['freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_keys = set() # set of synonyms to look for in the trie\n",
    "term_lookup = {} # mapping from each synonym to (A, b) where A is its type and b is its index in its respective ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, med in enumerate(med_list):\n",
    "    trie_keys.add(med)\n",
    "    term_lookup[med] = ('MEDICATION', i)\n",
    "for i, syns in enumerate(hpi_ontology['synonyms']):\n",
    "    if hpi_ontology.loc[i]['ignore']:\n",
    "        continue\n",
    "    for s in syns:\n",
    "        if len(s) < 3: # ignore short synonyms that might be ambiguous such as \"MI\" or \"AS\"\n",
    "            continue \n",
    "        trie_keys.add(s)\n",
    "        term_lookup[s] = ('DISEASE', i)\n",
    "for i, syns in enumerate(symptom_ontology['synonyms']):\n",
    "    if symptom_ontology.loc[i]['ignore']:\n",
    "        continue\n",
    "    for s in syns:\n",
    "        trie_keys.add(s)\n",
    "        term_lookup[s] = ('SYMPTOM', i)\n",
    "for i, lab in enumerate(lab_list):\n",
    "    trie_keys.add(lab)\n",
    "    term_lookup[lab] = ('LAB', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_trie = marisa_trie.Trie(trie_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synonyms = {\n",
    "    'DISEASE' : list(hpi_ontology['synonyms']), \n",
    "    'SYMPTOM' : list(symptom_ontology['synonyms']), \n",
    "    'LAB' : [[lab] for lab in lab_list],\n",
    "    'MEDICATION' : [[med] for med in med_list]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find clinical concepts retrospectively in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_concepts(md_comments):\n",
    "    concepts = {'DISEASE' : [], 'SYMPTOM' : [], 'LAB' : [], 'MEDICATION' : []}\n",
    "    blacklisted_toks = set()\n",
    "    tokens = md_comments.lower().split()\n",
    "    for i, tok in enumerate(tokens):\n",
    "        if i in blacklisted_toks:\n",
    "            continue\n",
    "        future_txt = ' '.join(tokens[i:])\n",
    "        potentials = search_trie.prefixes(unicode(future_txt))\n",
    "        if not potentials:\n",
    "            continue\n",
    "        best = max(potentials, key=len)\n",
    "        if len(future_txt) == len(best) or future_txt[len(best)] in ' ,;:.':\n",
    "            concept = term_lookup[best][0]\n",
    "            concepts[concept].append(best)\n",
    "            for j in range(len(re.split('(\\s|[\\.!\\?,;])', best))):\n",
    "                blacklisted_toks.add(j + i)\n",
    "    return concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure MRR, MAPK, and keystroke burden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ranking(suggested, term): \n",
    "    suggested.remove(term)\n",
    "    suggested.append(term)\n",
    "    return suggested\n",
    "\n",
    "def get_mrr(suggested, relevant):\n",
    "    if suggested is None or relevant is None:\n",
    "        return None\n",
    "    curr_suggested = suggested[:]\n",
    "    mrrs = []\n",
    "    for b in relevant:\n",
    "        mrr = (1.0/float(curr_suggested.index(b) - len(relevant) + 2) if curr_suggested.index(b) >= len(relevant) else 1.0)\n",
    "        curr_suggested = update_ranking(curr_suggested, b)\n",
    "        mrrs.append(mrr)\n",
    "    return np.mean(mrrs)\n",
    "\n",
    "def get_mapk(suggested, relevant):\n",
    "    curr_suggested = suggested[:]\n",
    "    mapks = []\n",
    "    for r in relevant:\n",
    "        mapk = len([i for i in curr_suggested[:curr_suggested.index(r) + 1] if i in relevant]) / float(curr_suggested.index(r) + 1)\n",
    "        mapks.append(mapk)\n",
    "    return np.mean(mapks)\n",
    "\n",
    "def get_num_keystrokes_singlequery(suggested, relevant_term, relevant_text, concept_type, k=3):\n",
    "    def word_in_set(word, syns):\n",
    "        for s in syns:\n",
    "            if word in s:\n",
    "                return True\n",
    "        return False\n",
    "    for i in range(len(relevant_text)):\n",
    "        word = relevant_text[:i]\n",
    "        new_suggested = [s for s in suggested if word_in_set(word, all_synonyms[concept_type][s])]\n",
    "        if relevant_term in new_suggested[:min(k, len(new_suggested))]:\n",
    "            return i\n",
    "    return len(relevant_text)\n",
    "\n",
    "def get_num_keystrokes(suggested, relevant, relevant_text, concept_type):\n",
    "    num_keystrokes = []\n",
    "    curr_suggested = suggested[:]\n",
    "    for r, r_text in zip(relevant, relevant_text):\n",
    "        num_keystrokes.append(get_num_keystrokes_singlequery(curr_suggested, r, r_text, concept_type))\n",
    "        curr_suggested = update_ranking(curr_suggested, r)\n",
    "    return np.mean(num_keystrokes)\n",
    "\n",
    "def get_metrics(ranking, ground_truth, ground_truth_text, concept_type):\n",
    "    mrr = get_mrr(ranking, ground_truth)\n",
    "    map_k = get_mapk(ranking, ground_truth)\n",
    "    num_keystrokes = get_num_keystrokes(ranking, ground_truth, ground_truth_text, concept_type)\n",
    "    return mrr, map_k, num_keystrokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # fix random seed so train/test split is preserved \n",
    "test_indices = np.random.choice(len(ed_visits_pkl), 25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics for labs, meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_autocompletes(visit_ix):\n",
    "    res = {\n",
    "        'LAB' : {'regular': None, 'spell' : None, 'freq' : None, 'contextual' : None},\n",
    "        'MEDICATION' : {'regular': None, 'spell' : None, 'freq' : None, 'contextual' : None},\n",
    "    } # initialize results dict with Nones\n",
    "    visit = ed_visits_pkl[visit_ix] # get visit level information \n",
    "    md_comments = visit['MDcomments'][0] # get MD comment, or ED note \n",
    "    visit_date = datetime.strptime(visit['Date'][0][14:24], '%Y-%m-%d') # get visit date \n",
    "    pid = visit['PatientID'][0] # get patientID (how to key into OMR)\n",
    "    if not md_comments:\n",
    "        return res\n",
    "    triage_assessment = visit['TriageAssessment'][0] # get triage assessment \n",
    "    vitals = {\n",
    "        'Age' : visit['Age'][0],\n",
    "        'Temp' : visit['TriageTemp'][0],\n",
    "        'RR' : visit['TriageRR'][0],\n",
    "        'Pulse' : visit['TriageHR'][0],\n",
    "        'O2Sat' : visit['TriageSaO2'][0],\n",
    "        'BP' : visit['TriageBP'][0] \n",
    "    } # get triage vitals \n",
    "    chief_complaint = list(ed_chief_complaints[visit_ix][-1]) # get chief complaint \n",
    "    chief_complaint = chief_complaint[0] if chief_complaint else None \n",
    "    concepts = find_concepts(md_comments)\n",
    "    disease_concepts = concepts.get('DISEASE')\n",
    "    symptom_concepts = concepts.get('SYMPTOM')\n",
    "    lab_concepts = concepts.get('LAB')\n",
    "    medication_concepts = concepts.get('MEDICATION')\n",
    "\n",
    "    for concept_type, ranker in [ ('LAB', lab_autocomplete), ('MEDICATION', medication_autocomplete)]:\n",
    "        ground_truth = [term_lookup[i][1] for i in concepts.get(concept_type)]\n",
    "        ground_truth_text = concepts.get(concept_type)\n",
    "        # for no autocomplete, spell based autocomplete, freq-based autocomplete, contextual autocomplete...\n",
    "        # find (MRR, MAPK, keystroke burden) \n",
    "        res[concept_type]['regular'] = None, None, np.mean([len(i) for i in ground_truth_text])\n",
    "        res[concept_type]['spell'] = get_metrics(ranker.get_spell_ranking(), ground_truth, ground_truth_text, concept_type)\n",
    "        res[concept_type]['freq'] = get_metrics(ranker.get_frequency_ranking(), ground_truth, ground_truth_text, concept_type)\n",
    "        res[concept_type]['contextual'] = None, None, None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyagop/.local/lib/python2.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/divyagop/.local/lib/python2.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "lab_med_res = [run_all_autocompletes(i) for i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_med_df = {}\n",
    "for dt in ['LAB', 'MEDICATION']:\n",
    "    for rank_type in ['regular', 'spell', 'freq', 'contextual']:\n",
    "        for metric_i, metric in enumerate(['mrr', 'map', 'keystrokes']):\n",
    "            col_header = '{}_{}_{}'.format(dt, rank_type, metric)\n",
    "            lab_med_df[col_header] = []\n",
    "            for r in lab_med_res:\n",
    "                if not r[dt][rank_type]:\n",
    "                    lab_med_df[col_header].append(None)\n",
    "                    continue\n",
    "                lab_med_df[col_header].append(r[dt][rank_type][metric_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy.stats as st\n",
    "conf_interval = lambda a : st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_med_df = pd.DataFrame(lab_med_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab_med_df.to_csv('labmed_only_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test symptom autocompletes against each other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_symptom_autocompletes(visit_ix):\n",
    "    res = {\n",
    "        'SYMPTOM_CC' : {'spell' : None, 'freq' : None, 'contextual' : None},\n",
    "        'SYMPTOM_CCVIT' : {'spell' : None, 'freq' : None, 'contextual' : None},\n",
    "        'SYMPTOM_LR' : {'regular': None, 'spell' : None, 'freq' : None, 'contextual' : None},\n",
    "        'SYMPTOM_NB' : {'regular': None, 'spell' : None, 'freq' : None, 'contextual' : None},\n",
    "    } # compare symptom models against each other, in the order presented in MLHC paper\n",
    "    visit = ed_visits_pkl[visit_ix]\n",
    "    md_comments = visit['MDcomments'][0]\n",
    "    visit_date = datetime.strptime(visit['Date'][0][14:24], '%Y-%m-%d')\n",
    "    pid = visit['PatientID'][0]\n",
    "    if not md_comments:\n",
    "        return res\n",
    "    triage_assessment = visit['TriageAssessment'][0]\n",
    "    vitals = {\n",
    "        'Age' : visit['Age'][0],\n",
    "        'Temp' : visit['TriageTemp'][0],\n",
    "        'RR' : visit['TriageRR'][0],\n",
    "        'Pulse' : visit['TriageHR'][0],\n",
    "        'O2Sat' : visit['TriageSaO2'][0],\n",
    "        'BP' : visit['TriageBP'][0],\n",
    "        'Sex' : visit['Sex'][0],\n",
    "        'Acuity' : visit['TriageAcuity'][0][0] if visit['TriageAcuity'][0] else None \n",
    "    }\n",
    "    chief_complaint = list(ed_chief_complaints[visit_ix][-1])\n",
    "    chief_complaint = chief_complaint[0] if chief_complaint else None \n",
    "    concepts = find_concepts(md_comments)\n",
    "    omr_notes, omr_buckets, omr_terms = [], None, None\n",
    "    disease_concepts = concepts.get('DISEASE')\n",
    "    symptom_concepts = concepts.get('SYMPTOM')\n",
    "    lab_concepts = concepts.get('LAB')\n",
    "    medication_concepts = concepts.get('MEDICATION')\n",
    "    for concept_type, ranker in [('SYMPTOM_CCVIT', symptom_autocomplete), ('SYMPTOM_CC', symptom_cc), ('SYMPTOM_LR', symptom_lr), ('SYMPTOM_NB', symptom_nb)]:\n",
    "        ground_truth = [term_lookup[i][1] for i in concepts.get('SYMPTOM')]\n",
    "        ground_truth_text = concepts.get('SYMPTOM')\n",
    "        res[concept_type]['regular'] = None, None, np.mean([len(i) for i in ground_truth_text])\n",
    "        res[concept_type]['spell'] = get_metrics(ranker.get_spell_ranking(), ground_truth, ground_truth_text, 'SYMPTOM')\n",
    "        res[concept_type]['freq'] = get_metrics(ranker.get_frequency_ranking(), ground_truth, ground_truth_text, 'SYMPTOM')\n",
    "        res[concept_type]['contextual'] = get_metrics(ranker.get_ranking(chief_complaint, vitals), ground_truth, ground_truth_text, 'SYMPTOM')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyagop/.local/lib/python2.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/divyagop/.local/lib/python2.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d5338eadb96d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msymptom_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrun_symptom_autocompletes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-db4c0d506c07>\u001b[0m in \u001b[0;36mrun_symptom_autocompletes\u001b[0;34m(visit_ix)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcept_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'regular'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mground_truth_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcept_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spell'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spell_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SYMPTOM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcept_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'freq'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frequency_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SYMPTOM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcept_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contextual'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchief_complaint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvitals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SYMPTOM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/BIDMC/jclinic/ContextualAutocomplete_MLHC2020/symptom_utils/symptom_autocomplete_utils.pyc\u001b[0m in \u001b[0;36mget_frequency_ranking\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_frequency_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymptom_umls_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymptom_ontology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchief_complaint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvitals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_get_loc\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2859\u001b[0m                                                       \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2860\u001b[0m                                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2861\u001b[0;31m                                                       dtype=new_values.dtype)\n\u001b[0m\u001b[1;32m   2862\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 data = sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 262\u001b[0;31m                                       raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/pandas/core/internals/construction.pyc\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    570\u001b[0m                         \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;31m# don't coerce Index types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/pandas/core/internals/construction.pyc\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, take_fast_path, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0;31m# perf shortcut as this is the most common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtake_fast_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmaybe_castable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/pandas/core/dtypes/cast.pyc\u001b[0m in \u001b[0;36mmaybe_castable\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_timedelta64_ns_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_POSSIBLY_CAST_DTYPES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/divyagop/.local/lib/python2.7/site-packages/numpy/core/_dtype.pyc\u001b[0m in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;31m# append bit counts to str, unicode, and void\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflexible\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_isunsized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/divyagop/.local/lib/python2.7/site-packages/numpy/core/numerictypes.pyc\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \"\"\"\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "symptom_results = [run_symptom_autocompletes(i) for i in test_indices[:5000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_df = {}\n",
    "for dt in ['SYMPTOM_CC', 'SYMPTOM_CCVIT', 'SYMPTOM_LR', 'SYMPTOM_NB']:\n",
    "    for rank_type in ['regular', 'spell', 'freq', 'contextual']:\n",
    "        for metric_i, metric in enumerate(['mrr', 'map', 'keystrokes']):\n",
    "            col_header = '{}_{}_{}'.format(dt, rank_type, metric)\n",
    "            symptom_df[col_header] = []\n",
    "            for r in symptom_results:\n",
    "                if not r.get(dt) or rank_type not in r[dt] or not r[dt][rank_type]:\n",
    "                    symptom_df[col_header].append(None)\n",
    "                    continue\n",
    "                symptom_df[col_header].append(r[dt][rank_type][metric_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_df = pd.DataFrame(symptom_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symptom_df.to_csv('symptom_only_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test HPI autocomplete models against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "omr_date_parser = lambda x : datetime.strptime(x['time'], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def run_hpi_autocompletes(visit_ix):\n",
    "    res = {\n",
    "        'HPI_NN' : {'regular' : None, 'spell' : None, 'freq' : None, 'contextual' : None},\n",
    "        'HPI_LR' : {'regular' : None, 'spell' : None, 'freq' : None, 'contextual' : None},\n",
    "        'HPI_LR_AUG' : {'regular': None, 'spell' : None, 'freq' : None, 'contextual' : None},\n",
    "    }\n",
    "    visit = ed_visits_pkl[visit_ix]\n",
    "    md_comments = visit['MDcomments'][0]\n",
    "    visit_date = datetime.strptime(visit['Date'][0][14:24], '%Y-%m-%d')\n",
    "    pid = visit['PatientID'][0]\n",
    "    if not md_comments:\n",
    "        return res\n",
    "    triage_assessment = visit['TriageAssessment'][0]\n",
    "    vitals = {\n",
    "        'Age' : visit['Age'][0],\n",
    "        'Temp' : visit['TriageTemp'][0],\n",
    "        'RR' : visit['TriageRR'][0],\n",
    "        'Pulse' : visit['TriageHR'][0],\n",
    "        'O2Sat' : visit['TriageSaO2'][0],\n",
    "        'BP' : visit['TriageBP'][0],\n",
    "        'Sex' : visit['Sex'][0],\n",
    "        'Acuity' : visit['TriageAcuity'][0][0] if visit['TriageAcuity'][0] else None \n",
    "    }\n",
    "    chief_complaint = list(ed_chief_complaints[visit_ix][-1])\n",
    "    chief_complaint = chief_complaint[0] if chief_complaint else None \n",
    "    concepts = find_concepts(md_comments)\n",
    "    omr_notes, omr_buckets, omr_terms = [], [], []\n",
    "    last_mentioned = {b : (visit_date - datetime(1, 1, 1)).days for b in range(hpi_autocomplete_lr_aug_model.max_bucket)}\n",
    "    # for each model relevance bucket, initialize the days since it was last mentioned as infinite\n",
    "    disease_concepts = concepts.get('DISEASE')\n",
    "    if len(disease_concepts) > 0 and pid in omr_data: # if there is OMR data...\n",
    "        last_omr_note = 0\n",
    "        for i, note in enumerate(omr_data[pid]):\n",
    "            if omr_date_parser(note) >= visit_date:\n",
    "                last_omr_note = i\n",
    "                break\n",
    "        omr_notes = [] if (last_omr_note==0) else omr_data[pid][:i] # filter OMR notes for those that occurred prior to ED visit date\n",
    "        for o in omr_notes:\n",
    "            o['time'] = omr_date_parser(o)\n",
    "        omr_buckets, omr_terms, last_mentioned = hpi_autocomplete_lr_aug_model.get_omr_buckets(omr_notes, omr_date_parser(note))\n",
    "    for concept_type, ranker in [('HPI_NN', hpi_autocomplete), ('HPI_LR', hpi_autocomplete_lr_model), ('HPI_LR_AUG', hpi_autocomplete_lr_aug_model)]:\n",
    "        ground_truth = [term_lookup[i][1] for i in concepts.get('DISEASE')]\n",
    "        ground_truth_text = concepts.get('DISEASE')\n",
    "        if concept_type == 'HPI_NN':\n",
    "            res[concept_type]['regular'] = None, None, np.mean([len(i) for i in ground_truth_text])\n",
    "            res[concept_type]['spell'] = get_metrics(ranker.get_spell_ranking(), ground_truth, ground_truth_text, 'DISEASE')\n",
    "            res[concept_type]['freq'] = get_metrics(ranker.get_frequency_ranking(), ground_truth, ground_truth_text, 'DISEASE')\n",
    "        res[concept_type]['contextual'] = get_metrics(ranker.get_ranking(triage_assessment, list(omr_buckets), omr_terms, last_mentioned), ground_truth, ground_truth_text, 'DISEASE')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_omr(visit_ix):\n",
    "    visit = ed_visits_pkl[visit_ix]\n",
    "    md_comments = visit['MDcomments'][0]\n",
    "    visit_date = datetime.strptime(visit['Date'][0][14:24], '%Y-%m-%d')\n",
    "    pid = visit['PatientID'][0]\n",
    "    triage_assessment = visit['TriageAssessment'][0]\n",
    "    if pid not in omr_data:\n",
    "        return False \n",
    "    for i, note in enumerate(omr_data[pid]):\n",
    "        if note['time'] < visit_date:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpi_utils.hpi_autocomplete_utils\n",
    "import hpi_utils.hpi_autocomplete_lr\n",
    "import hpi_utils.hpi_autocomplete_lr_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.20.4 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/anaconda3/envs/jclinic_py2/lib/python2.7/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.20.4 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "hpi_autocomplete = hpi_utils.hpi_autocomplete_utils.HPIAutocomplete()\n",
    "hpi_autocomplete_lr_model = hpi_utils.hpi_autocomplete_lr.HPIAutocomplete_LR()\n",
    "hpi_autocomplete_lr_aug_model = hpi_utils.hpi_autocomplete_lr_aug.HPIAutocomplete_LRAug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyagop/.local/lib/python2.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/divyagop/.local/lib/python2.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "hpi_results = []\n",
    "for i in test_indices[:2000]:\n",
    "    hpi_results.append(run_hpi_autocompletes(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpi_df = {}\n",
    "for dt in ['HPI_NN', 'HPI_LR', 'HPI_LR_AUG']:\n",
    "    for rank_type in ['regular', 'spell', 'freq', 'contextual']:\n",
    "        for metric_i, metric in enumerate(['mrr', 'map', 'keystrokes']):\n",
    "            col_header = '{}_{}_{}'.format(dt, rank_type, metric)\n",
    "            hpi_df[col_header] = []\n",
    "            for r in hpi_results:\n",
    "                if not r.get(dt) or rank_type not in r[dt] or not r[dt][rank_type]:\n",
    "                    hpi_df[col_header].append(None)\n",
    "                    continue\n",
    "                hpi_df[col_header].append(r[dt][rank_type][metric_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpi_df = pd.DataFrame(hpi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_omr(visit_ix):\n",
    "    visit = ed_visits_pkl[visit_ix]\n",
    "    md_comments = visit['MDcomments'][0]\n",
    "    visit_date = datetime.strptime(visit['Date'][0][14:24], '%Y-%m-%d')\n",
    "    pid = visit['PatientID'][0]\n",
    "    if not md_comments:\n",
    "        return None, None, None, None, None \n",
    "    hpi = md_comments.split('\\n')[0].lower()\n",
    "    concepts = find_concepts(hpi)\n",
    "    omr_notes, omr_buckets, omr_terms = [], [], []\n",
    "    last_mentioned = {b : (visit_date - datetime(1, 1, 1)).days for b in range(hpi_autocomplete_lr_aug_model.max_bucket)}\n",
    "    disease_concepts = concepts.get('DISEASE')\n",
    "    if len(disease_concepts) > 0 and pid in omr_data:\n",
    "        last_omr_note = 0\n",
    "        for i, note in enumerate(omr_data[pid]):\n",
    "            if note['time'] >= visit_date:\n",
    "                last_omr_note = i\n",
    "                break\n",
    "        omr_notes = [] if (last_omr_note==0) else omr_data[pid][:i]\n",
    "        omr_buckets, omr_terms, last_mentioned = hpi_autocomplete_lr_aug_model.get_omr_buckets(omr_notes, visit_date)\n",
    "    return len(omr_terms), len(concepts.get('DISEASE')), len(concepts.get('SYMPTOM')), len(concepts.get('LAB')), len(concepts.get('MEDICATION'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(data=count_df_data, columns=['num_omr_terms', 'num_tagged_disease', 'num_tagged_symp', 'num_tagged_labs', 'num_tagged_meds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = count_df.dropna()\n",
    "count_df['total_tagged'] = count_df['num_tagged_disease'] + count_df['num_tagged_symp'] + count_df['num_tagged_labs'] + count_df['num_tagged_meds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = count_df[count_df['num_omr_terms'] > 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jclinic_py2]",
   "language": "python",
   "name": "conda-env-jclinic_py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
